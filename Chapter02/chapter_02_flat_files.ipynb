{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c69649-aea2-4f7f-b812-586f3a6a6a79",
   "metadata": {},
   "source": [
    "## 2.1 Basics of pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a6d55e9-dcb6-45dc-be74-b24dd78d6daa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "\n",
    "# Create a fictional DataFrame \n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "        'Age': [25, 30, 35],\n",
    "        'City': ['Paris', 'New York', 'London']}  \n",
    "\n",
    "df = pd.DataFrame(data)  # Display the shape of the DataFrame \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f7310ee-ef39-443f-9406-8a3a5e585ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Name', 'Age', 'City'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the column names \n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9511b2c-3527-4d23-8f07-1b67c5d4b9c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=3, step=1)\n"
     ]
    }
   ],
   "source": [
    "# Display the row labels \n",
    "print(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b62feeee-56b1-4485-a2c0-5d8ed35de9d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name    object\n",
      "Age      int64\n",
      "City    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display the data types of the columns \n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e66e3d-5bdc-40b6-9a99-0fe58e7a97f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age      City\n",
      "0    Alice   25     Paris\n",
      "1      Bob   30  New York\n",
      "2  Charlie   35    London\n",
      "      Name  Age      City\n",
      "0    Alice   25     Paris\n",
      "1      Bob   30  New York\n",
      "2  Charlie   35    London\n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the DataFrame \n",
    "print(df.head()) \n",
    "\n",
    "# Display the last few rows of the DataFrame \n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be63d9f-e4f9-4311-b66c-3adf4a576c71",
   "metadata": {},
   "source": [
    "## 2.2 Read structured or flat files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb2d5ce-8525-4f5e-9918-853b6d92e313",
   "metadata": {},
   "source": [
    "Let's start by reading a simple and light CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd71feea-47b3-4acf-9239-bd47c74bcaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = './data/raw/source.csv'\n",
    "\n",
    "df = pd.read_csv(CSV_PATH, \n",
    "                 sep=';', \n",
    "                 encoding='utf-8')\n",
    "\n",
    "# We can then display a preview of the first few rows to ensure everything is read correctly\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcccce1a-c21d-473d-b404-2bf664e5227f",
   "metadata": {},
   "source": [
    "If file size exceed available RAM size, you will need to chunk the CSV to process it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f4ed33-f713-4bdd-bb84-2a26debe6b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 10000 # number of lines per chunk\n",
    "csv_path = 'big_file.csv'\n",
    "\n",
    "# Create an empty list to store modified chunks\n",
    "modified_chunks = []\n",
    "\n",
    "# Iterate over chunks\n",
    "for i, chunk in enumerate(pd.read_csv(csv_path, chunksize=chunk_size)):\n",
    "    # Apply modifications to the chunk (example: add 1 to a column named 'example_column')\n",
    "    chunk_modifie = chunk.apply(ma_fonction)\n",
    "\n",
    "    # Append the modified chunk to the list\n",
    "    chunk_modifie.to_csv(\n",
    "    f'./data/processed/chunk_modifie_{i}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d3a385-221b-48ae-82b7-c9bd1c10a2a5",
   "metadata": {},
   "source": [
    "It's the same logic for XLSX and XLS files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa7d9e-639f-4d76-b7e5-ecacd97f4e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "XLSX_PATH = './data/raw/results.xlsx'\n",
    "\n",
    "df = pd.read_excel(XLSX_PATH, \n",
    "\t\t\t\t   sheet_name='Results',\n",
    "\t\t\t\t   usecols=[1,2,3,7,8,9])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28667cf-e651-4c72-b5a9-adad5cbdf6aa",
   "metadata": {},
   "source": [
    "You can read JSON file with json standard python library or use pandas : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0924c3a-cb2c-4e6f-8293-38f74121be33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_with_pandas(file_path): \n",
    "    try: \n",
    "        dataframe = pd.read_json(file_path) \n",
    "        return dataframe \n",
    "    except FileNotFoundError: \n",
    "        print(f'The file \"{file_path}\" was not found.')\n",
    "        return None\n",
    "    except pd.errors.JSONDecodeError as e: \n",
    "        print(f'Error reading the JSON file with pandas: {e}') \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1697d7f1-e5b7-445c-9e48-02ee45f33b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234aa54a-d016-4c0f-b910-7464386ca8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def load_xml_file(file_path):\n",
    "    try:\n",
    "        tree = ET.parse(file_path)\n",
    "        return tree.getroot()\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error reading the XML file: {e}\")\n",
    "        return None\n",
    "\n",
    "def traverse_elements(parent_element):\n",
    "    for child in parent_element:\n",
    "        print(f\"Tag: {child.tag}, Text: {child.text}\")\n",
    "        traverse_elements(child)\n",
    "\n",
    "# Replace 'example.xml' with the path to your XML file\n",
    "xml_file = 'example.xml'\n",
    "root = load_xml_file(xml_file)\n",
    "\n",
    "if root is not None:\n",
    "    traverse_elements(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a6fac3-d756-4f25-bc39-f45fe62c6a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a38dd9-71c6-4968-9dfe-f36be86ad525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_xml_with_pandas(file_path):\n",
    "    try:\n",
    "        # Using Pandas' read_xml function to load the XML file\n",
    "        dataframe = pd.read_xml(file_path)\n",
    "        return dataframe\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading the XML file with Pandas: {e}\")\n",
    "        return None\n",
    "\n",
    "# Replace 'example.xml' with the path to your XML file\n",
    "xml_file = 'example.xml'\n",
    "xml_dataframe = load_xml_with_pandas(xml_file)\n",
    "\n",
    "if xml_dataframe is not None:\n",
    "    print(xml_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271f94d-1946-4cd8-8f09-6ee3648e6362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e08f19a-a15c-4858-ad01-1261d847b49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "PRÉCISIONS LIMINAIRES\n",
      "La mise à disposition du public d’un document administratif et des données publiques qu’il contient découle de \n",
      "deux types de règles : \n",
      "• les règles relatives à la publication, comme une formalité nécessaire pour l’entrée en vigueur d’un acte juridique \n",
      "ou le déclenchement d’un délai. Ainsi, l’article 1er du code civil dispose que les lois et, lorsqu’ils sont publiés au \n",
      "Journal officiel de la République française, les actes administratifs entrent, en principe, en vigueur à la date qu’ils \n",
      "fixent ou, à défaut, le lendemain de leur publication1. \n",
      "• les règles relatives au droit d’accès aux documents administratifs, qui comprend des obligations de communica-\n",
      "tion et de diffusion publique pour les administrations, impliquant notamment la mise en ligne des documents. En \n",
      "effet, avec l’adoption de la loi pour une République numérique du 7 octobre 2016, l’objectif de transparence, qui \n",
      "a présidé à l’adoption de la loi du 17 juillet 1978, consacre désormais le passage d’une logique de communication \n",
      "ponctuelle des documents administratifs, à une logique d’ouverture par défaut des informations détenues par les \n",
      "administrations, afin d’en permettre l’exploitation et la valorisation par les bénéficiaires du droit d’accès. \n",
      "Le présent guide porte exclusivement sur les modalités de mise en ligne et de réutilisation des documents adminis-\n",
      "tratifs et données publiques relevant d’une logique de droit d’accès.  Communément qualifiées sous l’appellation \n",
      "générique anglaise d’« open data », ces modalités visent des données librement accessibles, mises à disposition \n",
      "dans un format ouvert et réutilisable par toute personne. \n",
      "Depuis plusieurs années, de nombreux États se sont inscrits dans un mouvement de diffusion en ligne des informa-\n",
      "tions détenues par leurs administrations publiques. Ces politiques d’ouverture des données publiques poursuivent \n",
      "trois objectifs majeurs : \n",
      "• renforcer la transparence de l’action administrative et de la vie démocratique ; \n",
      "• identifier des leviers d’amélioration de l’organisation et de la gestion publiques ; \n",
      "• susciter l’innovation économique par la création de nouveaux services.\n",
      "En France, ce mouvement a d’abord été initié par les collectivités territoriales. L’État a engagé à compter des  \n",
      "années 2010 une politique fortement incitative, qui s’est notamment traduite par la mise en ligne de la plate-\n",
      "forme « data.gouv.fr », où plusieurs milliers de jeux de données sont désormais disponibles, et la mise en place de  \n",
      "nouvelles structures administratives (la direction interministérielle du numérique et du système d’information et de \n",
      "communication de l’État (DINSIC), la mission Etalab, l’administrateur général des données), dont le rôle est d’inciter \n",
      "les différents acteurs publics à mettre en ligne les informations qu’ils détiennent et de les accompagner dans la \n",
      "mise en œuvre de leurs projets. La France est aujourd’hui l’un des pays les plus en pointe en matière d’ouverture \n",
      "des données publiques. \n",
      "Le cadre juridique de cette ouverture des données publiques est constitué de deux ensembles :\n",
      "• les dispositions sur le droit d’accès aux documents administratifs, aujourd’hui codifiées au livre III du code des \n",
      "relations entre le public et l’administration (CRPA), auquel s’ajoutent de nombreuses législations spéciales ;\n",
      "• les dispositions sur la protection des données personnelles (RGPD23 et loi « Informatique et Libertés »), qui sont \n",
      "applicables dès lors que la mise en ligne concerne des documents administratifs ou des données publiques com-\n",
      "portant des informations relatives à des personnes identifiées ou susceptibles de l’être.\n",
      "Le volet n°1 du présent guide présente les modalités d’articulation de ces deux ensembles complémentaires, étant \n",
      "précisé que l’entrée en vigueur du RGPD n’a pas impacté le cadre juridique préexistant du droit d’accès aux docu-\n",
      "ments administratifs3.  Ce document et les fiches pratiques qui l’accompagneront feront l’objet d’une actualisation \n",
      "régulière au fil des évolutions légales ou jurisprudentielles.\n",
      "01  Voir également, par exemple, les dispositions des articles L. 2131-1, L. 3131-1 et L. 4141-1 du code général des collectivités territoriales (CGCT) au sujet du caractère \n",
      "exécutoires des actes des autorités communales, départementales et régionales.\n",
      "02  Règlement (UE) 2016/679 du Parlement européen et du Conseil du 27 avril 2016 relatif à la protection des personnes physiques à l’égard du traitement des données à \n",
      "caractère personnel et à la libre circulation de ces données, et abrogeant la directive 95/46/CE (règlement général sur la protection des données).\n",
      "03  L’article 86 du RGPD prévoit que « les données à caractère personnel figurant dans des documents officiels détenus par une autorité publique ou par un organisme public \n",
      "ou un organisme privé pour l’exécution d’une mission d’intérêt public peuvent être communiquées par ladite autorité ou ledit organisme conformément au droit de l’Union \n",
      "ou au droit de l’État membre auquel est soumis l’autorité publique ou l’organisme public, afin de concilier le droit d’accès du public aux documents officiels et le droit à la \n",
      "protection des données à caractère personnel au titre du présent règlement ».\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "\n",
    "pdf_file = open('./data/guide-open-data.pdf', 'rb')\n",
    "\n",
    "pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
    "\n",
    "# For example, we can access the number of pages in a document\n",
    "print(len(pdf_reader.pages))\n",
    "\n",
    "# Now we create a page object\n",
    "page_0 = pdf_reader.pages[2]\n",
    "\n",
    "# We extract the text from this page using the extract_text() method\n",
    "page_0_content = page_0.extract_text()\n",
    "\n",
    "print(page_0_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb2e948-9657-433b-aeca-5b36575178e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(page_0_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71ce6d4-a692-4569-9b26-c98b5dca955a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "\n",
    "PDF_PATH = './data/source.pdf'\n",
    "\n",
    "tables = tabula.read(PDF_PATH, pages=1)\n",
    "first_table = tables[0]\n",
    "\n",
    "tabula.convert_into(PDF_PATH, './data/processed/table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424b6c9-fd8a-4317-aefc-e7224a4514dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4a0a7c-c809-43b4-b81b-a48bf216a1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from img2table.ocr import TesseractOCR\n",
    "from img2table.document import Image\n",
    "\n",
    "# OCR Instantiation\n",
    "ocr = TesseractOCR(n_threads=1, lang=\"en\")\n",
    "\n",
    "# Document Instantiation (image or PDF for example)\n",
    "doc = Image(src)\n",
    "\n",
    "# Table Extraction\n",
    "table = doc.extract_tables(ocr=ocr,\n",
    "                           implicit_rows=False,\n",
    "                           borderless_tables=False,\n",
    "                           min_confidence=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
